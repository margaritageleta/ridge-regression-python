{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Upload data.\n",
    "df = pd.DataFrame(pd.read_csv('deathrate_instance_python.dat', header=None, sep=\"\\s+\"))\n",
    "df.columns = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'Y']\n",
    "# Define matrix X and vector Y.\n",
    "Y = df['Y']\n",
    "X = df.drop(columns=['Y'])\n",
    "# Add a column of ones.\n",
    "#X = pd.concat([X, pd.DataFrame({'O': np.ones(len(X))})], axis=1) \n",
    "# Transform dataframe into matrix.\n",
    "Ymat = Y.values\n",
    "Xmat = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss func loss(x)\n",
    "def loss_func (x):\n",
    "    \"\"\"\n",
    "    Objective function: loss / cost function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    w array of weights.\n",
    "    gamma array of intercepts.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The objective function loss(x) evaluated at {w, gamma}.\n",
    "    \n",
    "    \"\"\"\n",
    "    w = np.asarray(x[:-1]).T\n",
    "    gamma = x[-1]\n",
    "    \n",
    "    cost = (1/2) * ((Xmat @ w) + gamma - Ymat).T @ ((Xmat @ w) + gamma - Ymat)\n",
    "  \n",
    "    return np.squeeze(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_grad (x): \n",
    "    \"\"\"\n",
    "    Gradient of the objective function (loss / cost function).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A matrix with x arrays at the rows.\n",
    "    w array of weights.\n",
    "    gamma array of intercepts.\n",
    "    y array of f(x).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Array of the gradient of the objective function loss(x) \n",
    "    evaluated at {w, gamma}.\n",
    "    \n",
    "    \"\"\"\n",
    "    w = np.asarray(x[:-1]).T\n",
    "    gamma = x[-1]\n",
    "    \n",
    "    g_cost_comp1 = Xmat.T @ ((Xmat @ w) + gamma - Ymat)\n",
    "    g_cost_comp2 = np.ones(len(Ymat)).T @ ((Xmat @ w) + gamma - Ymat)\n",
    "    \n",
    "    return np.concatenate((g_cost_comp1, g_cost_comp2), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_hess (x):\n",
    "    \"\"\"\n",
    "    Hessian matrix of the objective function (loss / cost function).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    w array of weights.\n",
    "    gamma array of intercepts.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Matrix of the Hessian of the objective function loss(x) \n",
    "    evaluated at {w, gamma}.\n",
    "    \n",
    "    \"\"\"\n",
    "    w = np.asarray(x[:-1]).T\n",
    "    gamma = x[-1]\n",
    "    \n",
    "    block_top_left = Xmat.T @ Xmat\n",
    "    block_top_right = Xmat.T @ np.ones(len(Ymat))\n",
    "    \n",
    "    block_bottom_left = np.ones(len(Ymat)).T @ Xmat\n",
    "    block_bottom_right = len(Ymat)\n",
    "    \n",
    "    H = np.empty([len(x), len(x)])\n",
    "    \n",
    "    H[:-1,:-1] = block_top_left\n",
    "    H[:-1,-1] = block_top_right\n",
    "    \n",
    "    H[-1,:-1] = block_bottom_left\n",
    "    H[-1,-1] = block_bottom_right\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wopt = [0.48824,-0.0463881,0.102978,-0.0377061,0.00490736,-0.0339172,-0.255786,0.00564845,0.649708,-0.12622,0.213407,-0.207831,0.109842,0.376641,0.00995978,895.141]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61484.650716435746"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(wopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n",
      "(60, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.05322859e+04,  9.99806306e+02, -2.22295893e+03,  8.13127974e+02,\n",
       "       -1.05927484e+02,  7.31350810e+02,  5.51550115e+03, -2.10784096e+02,\n",
       "       -1.40146068e+04,  2.72154380e+03, -4.60357165e+03,  4.48211610e+03,\n",
       "       -2.36983501e+03, -8.12547179e+03, -2.16150552e+02, -2.28754456e-02])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_grad(wopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_hess(wopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cons_func (x):\n",
    "    \"\"\"\n",
    "    Constraint.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x array of weights and gamma.\n",
    "    Gamma will be ignored (x[-1]).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The constraint evaluated at x.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x[-1] = 0\n",
    "    w = np.asarray(x).T\n",
    "    return np.sum(w**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cons_jacobian (x):\n",
    "    \"\"\"\n",
    "    Gradient of the constraint.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x array of weights and gamma.\n",
    "    Gamma will be ignored (x[-1]).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The gradient of the constraint evaluated at x.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x[-1] = 0\n",
    "    w = np.asarray(x).T\n",
    "    return (2*w).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cons_hess (x, v):\n",
    "    \"\"\"\n",
    "    Product of the hessian of the constraint by an arbitrary vector.\n",
    "    It is needed for the minimize function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x array of weights and gamma.\n",
    "    Gamma will be ignored (x[-1]).\n",
    "    v vector of length = number of constraints.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The Hessian of the constraint evaluated at x by v[0].\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x[-1] = 0\n",
    "    w = np.asarray(x).T\n",
    "    H = (np.eye(w.shape[0])*2)\n",
    "    H[-1,-1] = 0\n",
    "    return v[0] * H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 314, function evaluations: 456, CG iterations: 1051, optimality: 9.01e+07, constraint violation: 2.30e-02, execution time: 0.45 s.\n",
      " barrier_parameter: 2.048000000000001e-09\n",
      " barrier_tolerance: 2.048000000000001e-09\n",
      "          cg_niter: 1051\n",
      "      cg_stop_cond: 2\n",
      "            constr: [array([1.02304613])]\n",
      "       constr_nfev: [456]\n",
      "       constr_nhev: [83]\n",
      "       constr_njev: [82]\n",
      "    constr_penalty: 1.0\n",
      "  constr_violation: 0.02304613284172996\n",
      "    execution_time: 0.4453599452972412\n",
      "               fun: 580796.2044913888\n",
      "              grad: array([-9.94626925e+05, -8.89928901e+05, -1.96002339e+06, -2.27754714e+05,\n",
      "       -8.58390398e+04, -2.87610861e+05, -2.10429325e+06, -9.12069718e+07,\n",
      "       -3.30456974e+05, -1.20311362e+06, -3.87587700e+05, -8.70050869e+05,\n",
      "       -5.26238947e+05, -1.27704025e+06, -1.50967026e+06, -2.61943093e+04])\n",
      "               jac: [array([[ 0.56804062,  0.18175717,  0.99391003,  0.1658011 ,  0.11150358,\n",
      "         0.06769815,  1.15448027,  0.18559022,  0.21722661,  0.67922756,\n",
      "         0.32467161, -0.10940345, -0.0299671 ,  0.17457221,  0.82435145,\n",
      "         0.        ]])]\n",
      "   lagrangian_grad: array([ 2.40199814e+06,  1.96896489e+05,  3.98310742e+06,  7.63660625e+05,\n",
      "        5.80901769e+05,  1.17193345e+05,  4.79897470e+06, -9.00972265e+07,\n",
      "        9.68459563e+05,  2.85835889e+06,  1.55380114e+06, -1.52423386e+06,\n",
      "       -7.05428604e+05, -2.33177682e+05,  3.41957718e+06, -2.61943093e+04])\n",
      "           message: '`xtol` termination condition is satisfied.'\n",
      "            method: 'tr_interior_point'\n",
      "              nfev: 456\n",
      "              nhev: 82\n",
      "               nit: 314\n",
      "             niter: 314\n",
      "              njev: 82\n",
      "        optimality: 90097226.53763838\n",
      "            status: 2\n",
      "           success: True\n",
      "         tr_radius: 6.634474019654785e-09\n",
      "                 v: [array([5979546.05559834])]\n",
      "                 x: array([ 0.28402031,  0.09087859,  0.49695502,  0.08290055,  0.05575179,\n",
      "        0.03384907,  0.57724014,  0.09279511,  0.10861331,  0.33961378,\n",
      "        0.1623358 , -0.05470173, -0.01498355,  0.0872861 ,  0.41217572,\n",
      "        0.        ])\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import LinearConstraint\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.optimize import NonlinearConstraint\n",
    "\n",
    "# Define hyperparamater t:\n",
    "t = 1\n",
    "\n",
    "## OPTIMIZATION ##\n",
    "# Assign initial random weights:\n",
    "w = np.squeeze(np.random.rand(1,16))\n",
    "\n",
    "# Define non linear constraint:\n",
    "nonlinear_constraint = NonlinearConstraint(cons_func, -np.inf, t, jac = cons_jacobian, hess = cons_hess) \n",
    "\n",
    "# Solve:\n",
    "sol = minimize(loss_func, wopt, method='trust-constr', jac=loss_grad, hess=loss_hess,\n",
    "               constraints=[nonlinear_constraint], options={'verbose': 1})\n",
    "# Output:\n",
    "print(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
